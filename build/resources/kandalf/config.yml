---
cluster:
  enabled:              true
  nodes:
    - "172.16.238.10:7946"
    - "172.16.238.11:7946"
    - "172.16.238.12:7946"
  # Optional. If empty, first available system's network interface will be used
  # Usefull with docker containers to bind not to "127.0.0.1", but to private network IP
  # bind_host:            "172.16.238.9"
  bind_port:            7946
  data_dir:             "/var/lib/kandalf"
  # How many connections in a pool
  max_pool:             3
  nb_snapshot:          2
  # Timeout of I/O deadlines (format: https://golang.org/pkg/time/#ParseDuration)
  timeout:              "10s"
log:
  level:                "debug"
  # `file`, `logstash` or `syslog` available at the moment
  adapter:              "file"
  file:
    # Path to the file to write logs to
    path:               "/var/log/kandalf.log"
    # The maximum number of days to retain old log files based on the timestamp encoded in their filename
    max_age:            0
    # The maximum number of old log files to retain
    max_backups:        3
    # The maximum size in megabytes of the log file before it gets rotated
    max_size:           0
  logstash:
    # `udp` or `tcp` supported
    protocol:           "tcp"
    # In `<host>:<port>` format
    address:            "logstash:5000"
  syslog:
    # `udp` or `tcp` supported
    protocol:           "udp"
    # In `<host>:<port>` format
    address:            "localhost:514"
kafka:
  brokers:
    - "kafka:9092"
  # The total number of times to retry sending a message.
  # Should be similar to the `message.send.max.retries` setting of the JVM producer.
  retry_max:            5
rabbitmq:
  urls:
    - "amqp://user:password@rmq"
queue:
  # The pause between attempts to flush in-memory queue to kafka
  flush_timeout:        "5s"
  # Max length of in-memory messages queue
  max_size:             10
  redis:
    # In `<host>:<port>` format
    address:            "redis:6379"
    # The name of the queue with failed messages
    key_name:           "failed_messages"
    # The pause between attempts to flush content of `queue.redis.key_name` to kafka
    flush_timeout:      "10s"
